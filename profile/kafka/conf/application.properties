#
# Data Collector configuration
#

content.stream.connector=rawdata

data.collector.worker.threads=50
data.collector.certs.directory=/certs
data.collector.print-execution-plan=true

#
# Rawdata Client configuration
#

rawdata.client.provider=kafka

#
# Rawdata Client Kafka configuration
#

kafka.server.port = dc-kafka:9992
kafka.max.block.ms = 5000
kafka.reconnect.backoff.max.ms = 10000
kafka.reconnect.backoff.ms = 5000
kafka.group.id = rawdata
kafka.key.deserializer.class = org.apache.kafka.common.serialization.StringDeserializer
kafka.value.deserializer.class=io.descoped.rawdata.kafka.PayloadDeserializer
kafka.auto.offset.reset = earliest
kafka.acks = all
kafka.delivery.timeout.ms = 10000
kafka.request.timeout.ms = 5000
kafka.batch.size = 65536
kafka.compression.type = none
kafka.linger.ms = 100
kafka.buffer.memory = 33554432
kafka.key.serializer.class = org.apache.kafka.common.serialization.StringSerializer
kafka.value.serializer.class=io.descoped.rawdata.kafka.PayloadSerializer
kafka.application.id = rawdata-stream"
kafka.default.key.serde.class = Serdes.String().getClass()
kafka.default.value.serde.class = Serdes.String().getClass()
kafka.enable.auto.commit  = false
